import numpy as np
import scipy.special
class neuralNetwork:
    
    #initialise the neural network
    def __init__(
            self,inputnodes,hiddennodes,outputnodes,
            learningrate):
        #set number of nodes in each input,hidden,output layer
        
        self.inodes = inputnodes
        self.hnodes = hiddennodes
        self.onodes = outputnodes
        
        #learning rate
        self.lr = learningrate
        #link weight matrices, wih and who 
        #weigth inside the arrays are w_i_j, where link is from node
        #i to node j in the next layer  w11 w21 etc
        #实现神经网络的心脏——链接权重矩阵
        self.wih = np.random.rand(self.hnodes,self.hnodes) - 0.5
        self.who = np.random.rand(self.onodes,self.hnodes) - 0.5
        # activation function is the sigmoid function
        self.activation_function = lambda x: scipy.special.expit(x)
        pass

    #train the neural network
    #
    def train(self,inputs_list,targets_list):
        #把输入列表转换成二维矩阵
        inputs = np.array(inputs_list,ndmin=2).T
        targets = np.array(targets_list,ndmin=2).T
        #计算隐藏层的输入和
        hidden_inputs = np.dot(self.wih,inputs)
        #计算隐藏层的信号激活输出
        hidden_outputs = self.activation_function(hidden_inputs)
        
        #计算输出层的输入和
        final_inputs = np.dot(self.who,hidden_outputs)
        #计算输出层的信号激活输出
        final_outputs = self.activation_function(final_inputs)
        
        #error is the (target - actual)
        output_errors = targets - final_outputs
        
        #hidden layer error is the output_errors,split by weights,recombined at hidden nodes
        hidden_errors = np.dot(self.who.T,output_errors)
        
        #update the weigths for the links between the hidden and output layers
        self.who += self.lr * np.dot((output_errors * final_outputs * (1.0 - final_outputs))
                                     ,np.transpose(hidden_outputs))
        
        #update the weights for the links between the input and hidden layers
        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs))
                                     ,np.transpose(inputs))
        
        pass
    #query the neural network
    #接受神经网络的输入，返回网络的输出
    def query(self,inputs_list):
        #把输入列表转换为二维矩阵,并转置
        inputs = np.array(inputs_list,ndmin=2).T #这里有些许疑问？只需传入一个参数——inputs_list
        #计算隐藏层的输入和
        hidden_inputs = np.dot(self.wih,inputs)
        #计算隐藏层的信号激活输出
        hidden_outputs = self.activation_function(hidden_inputs)
        
        #计算输出层的输入和
        final_inputs = np.dot(self.who,hidden_outputs)
        #计算输出层的信号激活输出
        final_outputs = self.activation_function(final_inputs)
        return final_outputs
        
    #---------------------------------------------------#
    # number of input hidden and output nodes
    #参数给定
    input_nodes = 3
    hidden_nodes = 3
    output_nodes = 3
    #learning rate is 0.3
    learning_rate = 0.3

    #create instance of neural network
    n = neuralNetwork(input_nodes,hidden_nodes,output_nodes,learning_rate)
    target_list = [1.23,3.34,2.23]
    input_list = [2.32,4.45,8.64]
